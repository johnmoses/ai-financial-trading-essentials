{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10: Tooling and Technology Stack for AI Trading Systems\n",
    "\n",
    "## 1. Vector Databases for Financial Data: Pinecone, Weaviate, Chroma\n",
    "\n",
    "Vector databases are specialized databases designed to store and query high-dimensional vectors, also known as embeddings. In finance, unstructured data like news articles, social media posts, and analyst reports can be converted into these vector embeddings using techniques like Word2Vec or BERT.\n",
    "\n",
    "Why they are useful\n",
    "\n",
    "Traditional databases are not efficient for searching based on semantic similarity. Vector databases allow for incredibly fast similarity searches. For example, you could find news articles that are semantically similar to a given article about a company's earnings report, even if they don't share the exact same keywords. This is powerful for identifying market sentiment, finding related news, and discovering new trading opportunities.\n",
    "\n",
    "Pinecone, Weaviate, Chroma\n",
    "\n",
    "These are popular vector database solutions. Pinecone and Weaviate are managed services, while Chroma is an open-source, in-process database that is easy to get started with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42864af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Similar News Articles ---\n",
      "- The Federal Reserve announced an interest rate hike to combat inflation.\n",
      "- New regulations in the energy sector are expected to impact oil prices.\n"
     ]
    }
   ],
   "source": [
    "# You would need to install chromadb and sentence-transformers first\n",
    "# pip install chromadb sentence-transformers\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize ChromaDB client and create a collection\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(\"financial_news\")\n",
    "\n",
    "# Example news articles\n",
    "documents = [\n",
    "    \"Apple's new iPhone sales exceed expectations, driving stock prices up.\",\n",
    "    \"The Federal Reserve announced an interest rate hike to combat inflation.\",\n",
    "    \"Tesla's quarterly earnings report shows a significant increase in vehicle deliveries.\",\n",
    "    \"New regulations in the energy sector are expected to impact oil prices.\",\n",
    "    \"Google's parent company, Alphabet, invests heavily in AI research.\"\n",
    "]\n",
    "\n",
    "# Create embeddings for the documents\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(documents)\n",
    "\n",
    "# Add the documents and embeddings to the collection\n",
    "collection.add(\n",
    "    embeddings=embeddings,\n",
    "    documents=documents,\n",
    "    ids=[f\"id{i}\" for i in range(len(documents))]\n",
    ")\n",
    "\n",
    "# Query the collection to find similar news articles\n",
    "query_text = \"What is the impact of interest rates on the economy?\"\n",
    "query_embedding = model.encode([query_text])[0]\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding.tolist()],\n",
    "    n_results=2\n",
    ")\n",
    "\n",
    "print(\"--- Similar News Articles ---\")\n",
    "for doc in results['documents'][0]:\n",
    "    print(f\"- {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. AI Frameworks and Agent Orchestration: OpenAI Agents, LangChain, CrewAI\n",
    "\n",
    "AI agent orchestration frameworks help in building complex applications by combining large language models (LLMs) with other tools and data sources. Instead of having a single monolithic model, you can have multiple specialized \"agents\" that can collaborate to perform a task.\n",
    "\n",
    "Why it's useful: In trading, you could have an agent that specializes in analyzing news sentiment, another that monitors market data, and a third that executes trades. These agents can be orchestrated to work together to form a sophisticated trading strategy.\n",
    "\n",
    "OpenAI Agents, LangChain, CrewAI: LangChain and CrewAI are popular open-source frameworks for building applications with LLMs. They provide tools for creating agents, managing prompts, and connecting to various data sources. OpenAI also provides its own tools for building agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108bb7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You would need to install langchain and langchain-openai first\n",
    "# pip install langchain langchain-openai\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain import hub\n",
    "\n",
    "# This is a conceptual example. You would need to set up your OpenAI API key.\n",
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "# Define a mock search tool\n",
    "def mock_financial_search(query: str) -> str:\n",
    "    \"\"\"A mock tool to search for financial information.\"\"\"\n",
    "    if \"Apple\" in query:\n",
    "        return \"Apple's stock price is currently $175. Recent news suggests strong iPhone sales.\"\n",
    "    else:\n",
    "        return \"Information not found.\"\n",
    "\n",
    "# Get the ReAct agent prompt\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "# Initialize the LLM and the tools\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = [\n",
    "    {\n",
    "        \"name\": \"FinancialSearch\",\n",
    "        \"func\": mock_financial_search,\n",
    "        \"description\": \"Searches for financial information about a company.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create the agent\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# Run the agent\n",
    "# agent_executor.invoke({\"input\": \"What is the latest news on Apple?\"})\n",
    "print(\"--- LangChain Agent (Conceptual) ---\")\n",
    "print(\"The code above shows how to create a simple agent with a mock search tool.\")\n",
    "print(\"To run it, you would need to have an OpenAI API key and the required libraries installed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Backtesting and Research Platforms: Zipline, Backtrader, QuantConnect\n",
    "\n",
    "Backtesting is the process of testing a trading strategy on historical data to see how it would have performed. It is a crucial step in the development of any trading strategy.\n",
    "\n",
    "Why it's important: \n",
    "Backtesting helps in evaluating the profitability and risk of a strategy before deploying it in a live market. It also helps in optimizing the strategy's parameters.\n",
    "\n",
    "Zipline, Backtrader, QuantConnect: \n",
    "These are popular platforms for backtesting trading strategies. Zipline and backtrader are open-source Python libraries, while QuantConnect is a cloud-based platform that supports multiple programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf4129b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Backtrader Example (Conceptual) ---\n",
      "The code above defines a simple moving average crossover strategy using backtrader.\n",
      "To run it, you would need to have historical data from a source like Yahoo Finance.\n"
     ]
    }
   ],
   "source": [
    "# You would need to install backtrader first\n",
    "# pip install backtrader\n",
    "import backtrader as bt\n",
    "import datetime\n",
    "\n",
    "# Create a simple moving average crossover strategy\n",
    "class SmaCross(bt.Strategy):\n",
    "    params = (('pfast', 10), ('pslow', 30),)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dataclose = self.datas[0].close\n",
    "        self.order = None\n",
    "        self.sma_fast = bt.indicators.SimpleMovingAverage(self.datas[0], period=self.p.pfast)\n",
    "        self.sma_slow = bt.indicators.SimpleMovingAverage(self.datas[0], period=self.p.pslow)\n",
    "        self.crossover = bt.indicators.CrossOver(self.sma_fast, self.sma_slow)\n",
    "\n",
    "    def next(self):\n",
    "        if self.order:\n",
    "            return\n",
    "\n",
    "        if not self.position:\n",
    "            if self.crossover > 0:\n",
    "                self.order = self.buy()\n",
    "        elif self.crossover < 0:\n",
    "            self.order = self.sell()\n",
    "\n",
    "# This is a conceptual example. To run it, you would need to have historical data.\n",
    "cerebro = bt.Cerebro()\n",
    "cerebro.addstrategy(SmaCross)\n",
    "#\n",
    "# # Create a Data Feed\n",
    "data = bt.feeds.YahooFinanceData(\n",
    "     dataname='AAPL',\n",
    "     fromdate=datetime.datetime(2020, 1, 1),\n",
    "     todate=datetime.datetime(2021, 1, 1)\n",
    " )\n",
    "\n",
    "cerebro.adddata(data)\n",
    "cerebro.broker.setcash(100000.0)\n",
    "# cerebro.run()\n",
    "# cerebro.plot()\n",
    "\n",
    "print(\"--- Backtrader Example (Conceptual) ---\")\n",
    "print(\"The code above defines a simple moving average crossover strategy using backtrader.\")\n",
    "print(\"To run it, you would need to have historical data from a source like Yahoo Finance.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Pipeline Tools: Apache Kafka, Apache Airflow, Prefect\n",
    "\n",
    "Data pipelines are essential for collecting, processing, and storing the vast amounts of data required for AI trading.\n",
    "\n",
    "Why they are critical: \n",
    "\n",
    "A robust data pipeline ensures that the trading models have access to timely and accurate data. It also helps in automating the process of data collection and pre-processing.\n",
    "\n",
    "Apache Kafka, Apache Airflow, Prefect: \n",
    "\n",
    "Apache Kafka is a distributed streaming platform that is used for building real-time data pipelines. Apache Airflow and Prefect are workflow management platforms that are used for orchestrating complex data pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30824d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data...\n",
      "Processing data...\n",
      "--- Prefect Data Pipeline ---\n",
      "   price  volume  price_change\n",
      "0    100    1000           NaN\n",
      "1    102    1200           2.0\n",
      "2    101    1100          -1.0\n",
      "3    103    1300           2.0\n",
      "4    105    1400           2.0\n"
     ]
    }
   ],
   "source": [
    "# You would need to install prefect first\n",
    "# pip install prefect\n",
    "from prefect import task, flow\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_data():\n",
    "    \"\"\"A mock task to fetch data.\"\"\"\n",
    "    print(\"Fetching data...\")\n",
    "    data = {'price': [100, 102, 101, 103, 105], 'volume': [1000, 1200, 1100, 1300, 1400]}\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def process_data(df):\n",
    "    \"\"\"A mock task to process data.\"\"\"\n",
    "    print(\"Processing data...\")\n",
    "    df['price_change'] = df['price'].diff()\n",
    "    return df\n",
    "\n",
    "def data_pipeline():\n",
    "    \"\"\"A simple data pipeline.\"\"\"\n",
    "    df = fetch_data()\n",
    "    processed_df = process_data(df)\n",
    "    print(\"--- Prefect Data Pipeline ---\")\n",
    "    print(processed_df)\n",
    "\n",
    "# Run the pipeline\n",
    "data_pipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. API Integration: Broker APIs, Market Data APIs, Alternative Data Providers\n",
    "\n",
    "APIs (Application Programming Interfaces) are the glue that connects the trading system to the outside world.\n",
    "\n",
    "Why it's important: \n",
    "\n",
    "Broker APIs are used to send orders and manage positions. Market data APIs provide real-time and historical price data. Alternative data providers offer a wide range of other data sources, such as news sentiment and satellite imagery.\n",
    "\n",
    "Reliable Integrations: \n",
    "\n",
    "It is crucial to have reliable and robust integrations with these APIs to ensure the smooth operation of the trading system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "553824e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting market data for AAPL...\n",
      "Market data: {'price': 175.5, 'volume': 50000000}\n",
      "Executing buy order for 100 shares of AAPL...\n",
      "Trade status: {'status': 'filled', 'price': 175.52}\n"
     ]
    }
   ],
   "source": [
    "def get_market_data(symbol):\n",
    "    \"\"\"A mock function to get market data.\"\"\"\n",
    "    print(f\"Getting market data for {symbol}...\")\n",
    "    # In a real application, you would make an API call to a market data provider here.\n",
    "    return {'price': 175.50, 'volume': 50000000}\n",
    "\n",
    "def execute_trade(symbol, side, quantity):\n",
    "    \"\"\"A mock function to execute a trade.\"\"\"\n",
    "    print(f\"Executing {side} order for {quantity} shares of {symbol}...\")\n",
    "    # In a real application, you would make an API call to a broker here.\n",
    "    return {'status': 'filled', 'price': 175.52}\n",
    "\n",
    "# Example Usage\n",
    "market_data = get_market_data('AAPL')\n",
    "print(f\"Market data: {market_data}\")\n",
    "\n",
    "trade_status = execute_trade('AAPL', 'buy', 100)\n",
    "print(f\"Trade status: {trade_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. MLOps for Trading: Model Versioning, A/B Testing, Continuous Training\n",
    "\n",
    "MLOps (Machine Learning Operations) is a set of practices that aims to deploy and maintain machine learning models in production reliably and efficiently.\n",
    "\n",
    "Why it's crucial for trading: \n",
    "\n",
    "In the fast-paced world of trading, it is essential to be able to quickly deploy new models, monitor their performance, and retrain them as needed.\n",
    "\n",
    "Model Versioning, A/B Testing, Continuous Training: \n",
    "\n",
    "Model versioning helps in keeping track of different versions of the models. A/B testing allows for testing new models on a small portion of the live data before deploying them to the entire system. Continuous training is the process of automatically retraining the models on new data to prevent model drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fb51ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as my_trading_model_v20250927070724.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "def save_model(model, model_name):\n",
    "    \"\"\"Saves a model with a version number.\"\"\"\n",
    "    version = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    filename = f\"{model_name}_v{version}.pkl\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Model saved as {filename}\")\n",
    "\n",
    "def load_model(filename):\n",
    "    \"\"\"Loads a model from a file.\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "# Example Usage\n",
    "class MyModel:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "\n",
    "# Create and save a model\n",
    "model_v1 = MyModel({'param1': 0.1})\n",
    "save_model(model_v1, 'my_trading_model')\n",
    "\n",
    "# Later, you can load a specific version of the model\n",
    "# loaded_model = load_model('my_trading_model_v20250927103000.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Development and Testing Environments: Docker, Kubernetes, CI/CD Pipelines\n",
    "\n",
    "A robust development and testing environment is essential for building reliable and scalable trading systems.\n",
    "\n",
    "- Docker: Docker is a containerization platform that allows you to package your application and its dependencies into a single container. This ensures that the application runs consistently across different environments.\n",
    "- Kubernetes: Kubernetes is a container orchestration platform that is used for deploying and managing containerized applications at scale.\n",
    "- CI/CD Pipelines: Continuous Integration/Continuous Delivery (CI/CD) pipelines automate the process of building, testing, and deploying your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b3a53d",
   "metadata": {
    "vscode": {
     "languageId": "xml"
    }
   },
   "outputs": [],
   "source": [
    "# Use an official Python runtime as a parent image\n",
    "FROM python:3.9-slim\n",
    "\n",
    "# Set the working directory in the container\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy the current directory contents into the container at /app\n",
    "COPY . /app\n",
    "\n",
    "# Install any needed packages specified in requirements.txt\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Make port 80 available to the world outside this container\n",
    "EXPOSE 80\n",
    "\n",
    "# Define environment variable\n",
    "ENV NAME World\n",
    "\n",
    "# Run app.py when the container launches\n",
    "CMD [\"python\", \"app.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Chapter 10 reviews essential tooling and technologies underlying AI trading infrastructure, enabling robust scalable, and efficient system development and deployment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mforge312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
