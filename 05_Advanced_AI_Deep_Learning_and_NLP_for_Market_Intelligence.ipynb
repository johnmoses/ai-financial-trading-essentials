{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 5: Advanced AI: Deep Learning and NLP for Market Intelligence\n",
        "\n",
        "## 1. Deep Learning Architectures for Financial Time Series: RNNs, LSTMs, CNNs, Transformers\n",
        "\n",
        "Deep learning offers a suite of architectures well-suited for financial time series analysis. Recurrent Neural Networks (RNNs) and their advanced variant, Long Short-Term Memory networks (LSTMs), are designed to capture temporal sequences and long-term dependencies, making them ideal for price forecasting. Convolutional Neural Networks (CNNs), typically used for image analysis, can be adapted to extract predictive features from time series data by treating it as a one-dimensional signal. More recently, Transformers, with their powerful attention mechanisms, have shown great promise by processing entire data sequences in parallel, allowing them to capture complex market patterns without the sequential limitations of RNNs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e6c5663a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-26 09:14:31.927460: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
            "2025-09-26 09:14:31.927501: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
            "2025-09-26 09:14:31.927504: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1758874471.927534  196658 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "I0000 00:00:1758874471.927585  196658 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
            "/Users/johnmoses/miniforge3/envs/mforge312/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,400</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m10,400\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,451</span> (40.82 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,451\u001b[0m (40.82 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,451</span> (40.82 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,451\u001b[0m (40.82 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Example: Building a simple LSTM model for time series prediction using TensorFlow/Keras\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# --- Generate synthetic time series data (e.g., stock prices) ---\n",
        "np.random.seed(42)\n",
        "data = np.random.randn(100).cumsum() + 50\n",
        "\n",
        "# --- Prepare data for LSTM ---\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back)]\n",
        "        X.append(a)\n",
        "        Y.append(dataset[i + look_back])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "look_back = 5\n",
        "X, y = create_dataset(data, look_back)\n",
        "X = np.reshape(X, (X.shape[0], X.shape[1], 1)) # Reshape for LSTM [samples, time steps, features]\n",
        "\n",
        "# --- Build and compile the LSTM model ---\n",
        "model = Sequential([\n",
        "    LSTM(50, input_shape=(look_back, 1)),\n",
        "    Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.summary()\n",
        "\n",
        "# --- Train the model (on this small dataset, it's just for demonstration) ---\n",
        "# model.fit(X, y, epochs=100, batch_size=1, verbose=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Attention Mechanisms and Sequence-to-Sequence Models for Price Prediction\n",
        "\n",
        "Attention mechanisms significantly enhance the predictive power of neural networks in finance. By allowing a model to dynamically weigh the importance of different past data points, attention helps it focus on the most influential historical events when forecasting future prices. This is particularly useful in sequence-to-sequence models, where the goal is to predict a future sequence of prices based on a historical one. The model can \"pay attention\" to critical past moments, such as an earnings announcement or a market shock, to improve its prediction accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "119529ff",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,400</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │ global_average_p… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │     \u001b[38;5;34m10,400\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m51\u001b[0m │ global_average_p… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,451</span> (40.82 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,451\u001b[0m (40.82 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,451</span> (40.82 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,451\u001b[0m (40.82 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Example: Adding a simple attention layer in a Keras model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, Dense, Attention, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# --- Define model inputs ---\n",
        "# Using the same data shape as the previous example\n",
        "look_back = 5\n",
        "input_shape = (look_back, 1)\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "# --- LSTM layer ---\n",
        "# return_sequences=True is required for the Attention layer to process the sequence\n",
        "lstm_out = LSTM(50, return_sequences=True)(inputs)\n",
        "\n",
        "# --- Attention layer ---\n",
        "# The Attention layer computes a weighted average of the LSTM outputs\n",
        "attention_out = Attention()([lstm_out, lstm_out])\n",
        "# We can then process the attention output, for example, by flattening or pooling\n",
        "# Here, we'll just use the output of the last time step after attention\n",
        "attention_out = tf.keras.layers.GlobalAveragePooling1D()(attention_out)\n",
        "\n",
        "\n",
        "# --- Output layer ---\n",
        "outputs = Dense(1)(attention_out)\n",
        "\n",
        "# --- Build and compile the model ---\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. NLP Fundamentals for Financial Text: Preprocessing, Domain-Specific Embeddings\n",
        "\n",
        "Applying Natural Language Processing (NLP) to financial texts like news articles, earnings reports, and social media feeds requires specialized techniques. Preprocessing goes beyond standard text cleaning to handle financial jargon, company tickers, and numerical data embedded in the text. Furthermore, generic word embeddings are often insufficient. Domain-specific embeddings, such as FinBERT, which are pre-trained on large financial corpora, provide a much richer and more contextually aware representation of financial language, leading to better model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text: Market rallies after a positive earnings report from $XYZ, with revenues up by 15%.\n",
            "Tokens: ['market', 'rallies', 'after', 'a', 'positive', 'earnings', 'report', 'from', '$', 'xyz', ',', 'with', 'revenues', 'up', 'by', '15', '%', '.']\n",
            "Filtered (no stop words): ['market', 'rallies', 'positive', 'earnings', 'report', '$', 'xyz', ',', 'revenues', '15', '%', '.']\n",
            "Stemmed: ['market', 'ralli', 'posit', 'earn', 'report', '$', 'xyz', ',', 'revenu', '15', '%', '.']\n"
          ]
        }
      ],
      "source": [
        "# Example: Tokenization, stop-word removal, and stemming for financial text\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download necessary NLTK data (if you haven't already)\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('stopwords')\n",
        "\n",
        "text = \"Market rallies after a positive earnings report from $XYZ, with revenues up by 15%.\"\n",
        "\n",
        "# --- Tokenization ---\n",
        "tokens = word_tokenize(text.lower())\n",
        "\n",
        "# --- Stop-word removal ---\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [w for w in tokens if not w in stop_words]\n",
        "\n",
        "# --- Stemming ---\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_tokens = [stemmer.stem(w) for w in filtered_tokens]\n",
        "\n",
        "print(\"Original Text:\", text)\n",
        "print(\"Tokens:\", tokens)\n",
        "print(\"Filtered (no stop words):\", filtered_tokens)\n",
        "print(\"Stemmed:\", stemmed_tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Advanced Sentiment Analysis: Aspect-Based Sentiment, Entity-Specific Analysis\n",
        "\n",
        "Aspect-based sentiment analysis offers a more granular view than simple positive or negative classifications. In a financial context, this means identifying sentiment towards specific entities or topics within a document. For example, a single earnings report might express positive sentiment about a company's revenue growth but negative sentiment regarding its increasing debt. By distinguishing between these aspects, traders can gain more precise and actionable insights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2b25b980",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Sentiment: 0.14\n",
            "Revenue Aspect Sentiment: 0.00\n",
            "Product Aspect Sentiment: 0.14\n"
          ]
        }
      ],
      "source": [
        "# Example: Using TextBlob to get sentiment polarity\n",
        "from textblob import TextBlob\n",
        "\n",
        "# A sentence with mixed sentiment\n",
        "text1 = \"Apple's revenue is soaring, but their new product is facing criticism.\"\n",
        "blob1 = TextBlob(text1)\n",
        "\n",
        "# Analyze sentiment of the whole sentence\n",
        "print(f\"Overall Sentiment: {blob1.sentiment.polarity:.2f}\") # Polarity is between -1 (negative) and 1 (positive)\n",
        "\n",
        "# Analyze sentiment of different aspects (by splitting the sentence)\n",
        "text_revenue = \"Apple's revenue is soaring\"\n",
        "text_product = \"their new product is facing criticism\"\n",
        "blob_revenue = TextBlob(text_revenue)\n",
        "blob_product = TextBlob(text_product)\n",
        "\n",
        "print(f\"Revenue Aspect Sentiment: {blob_revenue.sentiment.polarity:.2f}\")\n",
        "print(f\"Product Aspect Sentiment: {blob_product.sentiment.polarity:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Event Detection and Information Extraction from Financial News and Reports\n",
        "\n",
        "Automated event detection from unstructured text is a powerful tool for generating trading signals. This involves using NLP techniques like Named Entity Recognition (NER) to identify and categorize key information, such as company names, executive mentions, and significant financial events (e.g., \"merger,\" \"acquisition,\" \"FDA approval\"). By extracting this structured information in real-time, algorithms can react to market-moving news faster than human traders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "eda812d2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected Entities:\n",
            "- Tesla (ORG)\n",
            "- Elon Musk (PERSON)\n",
            "- 5 (CARDINAL)\n",
            "- 10% (PERCENT)\n"
          ]
        }
      ],
      "source": [
        "# Example: Using spaCy for Named Entity Recognition on a news headline\n",
        "# You may need to install spaCy and its model: pip install spacy && python -m spacy download en_core_web_sm\n",
        "import spacy\n",
        "\n",
        "# Load the English NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"Tesla's CEO, Elon Musk, announced a 5-for-1 stock split, sending the share price up by 10%.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "# Print the detected entities and their labels\n",
        "print(\"Detected Entities:\")\n",
        "for ent in doc.ents:\n",
        "    print(f\"- {ent.text} ({ent.label_})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Multi-Modal Data Fusion: Combining Price Action, Volume, and Textual Signals\n",
        "\n",
        "Fusing different data types, or modalities, creates a more holistic view of the market. By combining quantitative data (like price and volume) with qualitative data (like sentiment scores from news articles), models can make more informed predictions. This approach allows the textual sentiment to provide context for price movements, leading to more robust models that can better understand the \"why\" behind market fluctuations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "97f9d92e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ numerical_input     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ textual_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ numerical_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ textual_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ numerical_input     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ textual_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ numerical_input[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ textual_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m384\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">929</span> (3.63 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m929\u001b[0m (3.63 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">929</span> (3.63 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m929\u001b[0m (3.63 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Example: Conceptual structure of a Keras model that fuses numerical and textual data\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# --- Define inputs for different data modalities ---\n",
        "# Numerical input (e.g., past 5 days of price and volume)\n",
        "numerical_input = Input(shape=(10,), name='numerical_input') # 5*2=10 features\n",
        "# Textual input (e.g., a single sentiment score for the day)\n",
        "textual_input = Input(shape=(1,), name='textual_input')\n",
        "\n",
        "# --- Concatenate all inputs ---\n",
        "concatenated = concatenate([numerical_input, textual_input])\n",
        "\n",
        "# --- Dense layers for processing the fused data ---\n",
        "dense1 = Dense(32, activation='relu')(concatenated)\n",
        "dense2 = Dense(16, activation='relu')(dense1)\n",
        "output = Dense(1, activation='linear', name='output')(dense2) # Predict next day's price\n",
        "\n",
        "# --- Build and compile the model ---\n",
        "model = Model(inputs=[numerical_input, textual_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Evaluation Frameworks for Deep Learning Trading Models\n",
        "\n",
        "Evaluating a deep learning-based trading model requires more than just standard machine learning metrics. A robust framework must assess the model's profitability and stability in a realistic trading environment. This includes analyzing risk-adjusted returns (e.g., Sharpe ratio), maximum drawdown, and the impact of transaction costs. Rigorous backtesting, with careful attention to avoiding look-ahead bias and overfitting, is essential to ensure the model is genuinely predictive and not just curve-fitted to historical data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "28d4c897",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Annualized Sharpe Ratio: -0.06\n",
            "Maximum Drawdown: -16.81%\n"
          ]
        }
      ],
      "source": [
        "# Example: Function to calculate Sharpe Ratio and Max Drawdown\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_performance_metrics(returns, risk_free_rate=0.0):\n",
        "    \"\"\"Calculates Sharpe Ratio and Max Drawdown for a series of returns.\"\"\"\n",
        "    # --- Sharpe Ratio ---\n",
        "    # Assumes daily returns\n",
        "    mean_return = returns.mean()\n",
        "    std_dev = returns.std()\n",
        "    sharpe_ratio = (mean_return - risk_free_rate) / std_dev * np.sqrt(252) # Annualized\n",
        "\n",
        "    # --- Max Drawdown ---\n",
        "    cumulative_returns = (1 + returns).cumprod()\n",
        "    peak = cumulative_returns.expanding(min_periods=1).max()\n",
        "    drawdown = (cumulative_returns/peak) - 1\n",
        "    max_drawdown = drawdown.min()\n",
        "    \n",
        "    return sharpe_ratio, max_drawdown\n",
        "\n",
        "# --- Simulate some strategy returns ---\n",
        "np.random.seed(42)\n",
        "strategy_returns = pd.Series(np.random.randn(252) / 100)\n",
        "\n",
        "# --- Calculate and print metrics ---\n",
        "sharpe, mdd = calculate_performance_metrics(strategy_returns)\n",
        "print(f\"Annualized Sharpe Ratio: {sharpe:.2f}\")\n",
        "print(f\"Maximum Drawdown: {mdd:.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summary\n",
        "\n",
        "This chapter outlines advanced deep learning architectures and NLP techniques applied to financial market intelligence, supplemented with practical text processing examples."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mforge312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
